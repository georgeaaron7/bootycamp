Here is the curriculum and instructions for Day 2 .
-----

## Day 2: Neural Network Fundamentals & CNN Basics

The core goal for Day 2 is to move from environment setup to core concepts. You will implement the mathematical building blocks of Neural Networks (Activation Functions) and the fundamental operation behind Computer Vision (Convolution) using Python.

### ðŸ§  Task 1: Conceptual Foundation

Before writing code, you must understand the mathematical operations that power deep learning.
Study Topics:

1.  Activation Functions:
       Sigmoid: Understanding how it squashes numbers between 0 and 1 (useful for probabilities).
       ReLU (Rectified Linear Unit): Understanding why it is the default for hidden layers (solving the vanishing gradient problem).
2.  The Convolution Operation:
       Understanding how a Kernel (Filter) slides over an input image.
       Understanding how element-wise multiplication and summation create a Feature Map.

### ðŸ Task 2: Implementation (Python)

You will create a Python script that manually performs these mathematical operations. This ensures you understand the "magic" happening under the hood of libraries like PyTorch or TensorFlow.

Navigate to the folder:

```bash
# Ensure you are in the repo root first
cd Day-02/
```

(If the folder does not exist, create it: `mkdir Day-02` then `cd Day-02`)

Create the file: `nn_math.py`

Coding Requirements:
Your script must include functions for the following logic (you may use NumPy if you have it installed, or standard Python lists):

1.  `sigmoid(x)`: Returns $\frac{1}{1 + e^{-x}}$
2.  `relu(x)`: Returns $x$ if $x > 0$, else $0$.
3.  `convolve(image, kernel)`:
       Define a small 5x5 "image" (matrix).
       Define a 3x3 "kernel" (e.g., a vertical edge detector).
       Write the nested loops to slide the kernel over the image and calculate the output feature map.

### ðŸ’¾ Task 3: Day 2 Submission using Feature Branching

From today onwards, we strictly enforce the Feature Branch Workflow. Do not commit directly to `main`.

#### 1\. Synchronization and Branch Creation

Start by ensuring your local code is up to date with the course `upstream`.

Switch to main:

```bash
git checkout main
```

Pull Updates from Upstream:
(This downloads the instructions or starter files for Day 2 if the instructors added them).

```bash
git pull upstream main
```

Create New Branch:
Naming Convention: `feat/day-<D>-<your-name>`

```bash
git checkout -b feat/day-02-aaron
```

#### 2\. Complete the Task & Commit

Once you have written and tested your `nn_math.py` script:

Stage and Commit Changes:

```bash
git add .
git commit -m "feat(day02): Implemented Sigmoid, ReLU and 2D Convolution"
```

#### 3\. Push the New Branch

Push your feature branch to your personal fork (`origin`).

```bash
git push -u origin feat/day-02-aaron
```

#### 4\. Open the Pull Request (PR)

Go to your fork's GitHub page. You will see the banner to Compare & Pull Request.

   Set PR Targets: From `feat/day-02-aaron` (your fork) â†’ `main` (original repo).
   Set PR Title:
    `[D02] Aaron - NN Math and Convolution Implementation`
   Description: Briefly explain that you implemented the activation functions and the convolution loop manually.
   Create PR: Click Create pull request.